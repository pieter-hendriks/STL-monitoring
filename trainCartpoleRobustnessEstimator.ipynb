{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "from stl.signals import Signal\n",
    "from stl.utility import Interval\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import antlr4 as a4\n",
    "import stl\n",
    "from examples.cartpole.data_converted import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINITIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeSampleSize(dataset, windowSize):\n",
    "\tcount = 0\n",
    "\tfor entry in dataset:\n",
    "\t\tsignal: Signal = entry[0][0]\n",
    "\t\tlastTime = signal.computeLargestTimeBefore(signal.getTime(-1) - windowSize)\n",
    "\t\tcount += signal.computeIndexForTime(lastTime) + 1\n",
    "\treturn count\n",
    "\n",
    "class MyOutputActivationFunctor(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef forward(self, prediction):\n",
    "\t\t\"\"\" Expects prediction to be a torch.Tensor;\n",
    "\t\tShould contain one batch worth of data, each individual prediction\n",
    "\t\tis a combination of [mean, variance].\n",
    "\t\tSo, overall, should be a Tensor of size [x, 2].\n",
    "\t\tOutput is that same dimension.\n",
    "\t\tprediction[:,0] is unchanged.\n",
    "\t\tprediction[:,1] is returned as (prediction[:,1])^2 + self.eps\n",
    "\t\t\n",
    "\t\tThis method simply ensures that the returned value will always be positive, as required by GaussianNLLLoss.\"\"\"\n",
    "\t\tout = torch.zeros_like(prediction)\n",
    "\t\tout[:,0] = prediction[:,0]\n",
    "\t\tout[:,1] = torch.square(prediction[:,1])\n",
    "\t\treturn out\n",
    "\t\t\n",
    "\n",
    "class CartpoleRobustnessEstimator(torch.nn.Module):\n",
    "\t\"\"\" Estimator for the cart pole robustness. \"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.eps = 1e-6\n",
    "\t\tself.convActivation = torch.nn.ReLU()\n",
    "\t\tself.fcActivation = torch.nn.ReLU()\n",
    "\t\tself.lossFunction = torch.nn.GaussianNLLLoss(eps=self.eps)\n",
    "\t\tself.output = MyOutputActivationFunctor()\n",
    "\t\tself.model = torch.nn.Sequential(\n",
    "\t\t\t\ttorch.nn.Conv1d(2, 4, 10),\n",
    "\t\t\t\tself.convActivation,\n",
    "\t\t    torch.nn.MaxPool1d(kernel_size=5, stride=2, padding=0),  #\n",
    "\t\t\t\tself.convActivation,\n",
    "\t\t\t\ttorch.nn.Conv1d(4, 4, 5),\n",
    "\t\t    torch.nn.AdaptiveMaxPool1d(25),  #\n",
    "\t\t\t\ttorch.nn.Flatten(),\n",
    "\t\t\t\tself.fcActivation,\n",
    "\t\t\t\ttorch.nn.Linear(100, 256),\n",
    "\t\t\t\tself.fcActivation,\n",
    "\t\t\t\ttorch.nn.Linear(256, 2),\n",
    "\t\t\t\tself.output\n",
    "\t\t).cuda()\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tprediction = self.model(x)\n",
    "\t\treturn prediction\n",
    "\n",
    "\tdef train(self, dataSet, batchSize, epochCount):\n",
    "\t\t\"\"\"\n",
    "\t\tTrains the model on the entirety of the given data set.\n",
    "\t\tExpected formats: dataSet: List[Tensor[Size(2,variable)]], results: List[Tensor[Size(1,)]], batchSize: unsigned integer\n",
    "\t\t\"\"\"\n",
    "\t\tself.model.train()\n",
    "\t\tself.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-7)\n",
    "\t\tlosses = []\n",
    "\t\tepochIndex = 0\n",
    "\t\twhile epochIndex < epochCount:\n",
    "\t\t\t# Randomly go through the data\n",
    "\t\t\tpermutedIndices = torch.randperm(len(dataSet))\n",
    "\t\t\tlosses.append([])\n",
    "\t\t\tfor i in range(0, len(dataSet), batchSize):\n",
    "\t\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\t\t# Indices for the current batch\n",
    "\t\t\t\tindices = permutedIndices[i: i+batchSize]\n",
    "\t\t\t\t# Create the input tensor and target tensor\n",
    "\t\t\t\tbatch = torch.cat(tuple(dataSet[i][0] for i in indices), dim = 0)\n",
    "\t\t\t\ttargets = torch.cat(tuple(dataSet[i][1] for i in indices))\n",
    "\t\t\t\t# Then, using that input, get a prediction\n",
    "\t\t\t\tpredictions = self.forward(batch)\n",
    "\t\t\t\tmeans = predictions[:,0]\n",
    "\t\t\t\tvariances = predictions[:,1]\n",
    "\t\t\t\t# Compute the loss\n",
    "\t\t\t\tloss = self.lossFunction(means, targets, variances)\n",
    "\t\t\t\t# Back-propagation\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\tself.optimizer.step()\n",
    "\t\t\t\t# Storage for visualizing\n",
    "\t\t\t\tlosses[-1].append(loss.item())\n",
    "\t\t\tprint(f\"Completed epoch {epochIndex}\")\n",
    "\t\t\tepochIndex += 1\n",
    "\t\treturn losses\n",
    "\n",
    "\tdef test(self, dataSet):\n",
    "\t\t\"\"\"\n",
    "\t\tTests the model. Prints performance stats.\n",
    "\t\t\"\"\"\n",
    "\t\tself.model.eval()\n",
    "\t\tdataIndex = 0\n",
    "\t\toutputs = []\n",
    "\t\tfor entry in dataSet:\n",
    "\t\t\tprediction = self.forward(entry[0])\n",
    "\t\t\toutputs.append((prediction.squeeze(), entry[1].item()))\n",
    "\t\t\tdataIndex += 1\n",
    "\t\t\tif dataIndex % 5000 == 0:\n",
    "\t\t\t\tprint(f\"Handled {dataIndex} out of {len(dataSet)} samples\")\n",
    "\t\tprint(f\"Handled all samples: {dataIndex} out of {len(dataSet)}\")\n",
    "\t\treturn outputs\n",
    "\n",
    "def preprocess(dataset, windowSize):\n",
    "\t\"\"\" Expected data in-format List[Tuple(List[Signal, Signal], Signal)]\n",
    "\tout-format: List[Tensor[values, values], Tensor[labelvalues]]\"\"\"\n",
    "\t# This behaviour is cartpole specific, since the data sets differ between environments.\n",
    "\tentry: Tuple[Tuple[Signal, Signal], Signal]\n",
    "\tresults = []\n",
    "\t# Iterate over data and find the longest signal\n",
    "\t# So we can null-pad the tensors\n",
    "\t\n",
    "\tlongestSignal = 0\n",
    "\tfor entry in dataset:\n",
    "\t\tentry[0][0], entry[0][1] = Signal.computeComparableSignals(entry[0][0], entry[0][1])\n",
    "\t\tfor cp in entry[0][0].getCheckpoints():\n",
    "\t\t\tlongestSignal = max(\n",
    "\t\t\t\tentry[0][0].computeInterval(Interval(cp.getTime(), cp.getTime() + windowSize)).getCheckpointCount(), #\n",
    "\t\t\t\tentry[0][1].computeInterval(Interval(cp.getTime(), cp.getTime() + windowSize)).getCheckpointCount(), #\n",
    "\t\t\t\tlongestSignal #\n",
    "\t\t\t)\n",
    "\tfor entry in dataset:\n",
    "\t\tpSignal: Signal = entry[0][0]\n",
    "\t\tcSignal: Signal = entry[0][1]\n",
    "\t\tlabels = entry[1]\n",
    "\t\ti = 0\n",
    "\t\t# pSignal and cSignal now have matching timestamps\n",
    "\t\twhile pSignal.getTime(-1) >= pSignal.getTime(i) + windowSize:  # Also applies to cSignal\n",
    "\t\t\tinterval = Interval(pSignal.getTime(i), pSignal.getTime(i) + windowSize)\n",
    "\t\t\tpIn = pSignal.computeInterval(interval)\n",
    "\t\t\tcIn = cSignal.computeInterval(interval)\n",
    "\t\t\tinTensor = torch.tensor([[pIn.getValues() + ([0] * (longestSignal - pIn.getCheckpointCount())), cIn.getValues() + ([0] * (longestSignal - cIn.getCheckpointCount()))]]).cuda()\n",
    "\t\t\toutTensor = torch.tensor([labels.computeInterpolatedValue(pSignal.getTime(i))]).cuda()\n",
    "\t\t\tresults.append((inTensor, outTensor))\n",
    "\t\t\ti += 1\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-import data and write to file ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = data[:-10]\n",
    "testData = data[-10:]\n",
    "\n",
    "trainData = preprocess(trainData, 50)\n",
    "testData = preprocess(testData, 50)\n",
    "with open(\"cartpoleTrainData.pickle\", \"wb\") as f:\n",
    "\ttorch.save(trainData, f, pickle_module=dill, pickle_protocol=dill.HIGHEST_PROTOCOL)\n",
    "with open(\"cartpoleTestData.pickle\", \"wb\") as f:\n",
    "\ttorch.save(testData, f, pickle_module=dill, pickle_protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL LOAD ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFileName = \"cartpoleEstimator.pickle\"\n",
    "if os.path.exists(saveFileName):\n",
    "\twith open(saveFileName, 'rb') as f:\n",
    "\t\testimator = torch.load(f, pickle_module=dill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6)\n",
    "estimator = CartpoleRobustnessEstimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFileName = \"cartpoleEstimator.pickle\"\n",
    "with open(saveFileName, \"wb\") as f:\n",
    "\ttorch.save(estimator, f, pickle_module=dill, pickle_protocol=dill.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOADING ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cartpoleTrainData.pickle\", \"rb\") as f:\n",
    "\ttrainData = torch.load(f, pickle_module=dill, map_location='cuda:0')\n",
    "with open(\"cartpoleTestData.pickle\", \"rb\") as f:\n",
    "\ttestData = torch.load(f, pickle_module=dill, map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN THE MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = estimator.train(trainData, batchSize=256, epochCount=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "lossPerBatch = [l for x in losses for l in x]\n",
    "ax.plot(lossPerBatch, label=\"Loss per batch\", color='blue')\n",
    "ax.plot(range(0, len(lossPerBatch), math.ceil(len(lossPerBatch) / len(losses))), [sum(x) / len(x) for x in losses], label=\"Mean loss per epoch\", color='red')\n",
    "ax.set_xlabel(\"Batch Index\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_title(\"Cartpole training performance\")\n",
    "\n",
    "\n",
    "xticks = [0, 20000, 40000, 60000, 80000, 100000, 120000, 140000]\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlabel(\"Epoch index\")\n",
    "ax2.set_xlim(ax.get_xlim())\n",
    "ax2.set_xticks(xticks)\n",
    "ax2.set_xticklabels([math.ceil(x * len(losses) / len(lossPerBatch)) for x in xticks])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST THE MODEL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "testResults = estimator.test(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Visualization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = list(range(len(testResults)))\n",
    "plt.plot(times, [x[1] for x in testResults], label=\"Computed Robustness\", color='red')\n",
    "y1 = [x[0][0].item() + math.sqrt(x[0][1].item()) for x in testResults]\n",
    "y2 = [x[0][0].item() - math.sqrt(x[0][1].item()) for x in testResults]\n",
    "plt.fill_between(times, y1, y2, color='blue', alpha=0.5, label=u\"Estimated Mean \\u00B1 \\u03C3\")\n",
    "y1 = [x[0][0].item() + 2*math.sqrt(x[0][1].item()) for x in testResults]\n",
    "y2 = [x[0][0].item() - 2*math.sqrt(x[0][1].item()) for x in testResults]\n",
    "plt.fill_between(times, y1, y2, color='blue', alpha=0.1, label=u\"Estimated Mean \\u00B1 2*\\u03C3\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Robustness\")\n",
    "plt.title(\"Estimated vs Computed Robustness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show amount of misses in test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = {}\n",
    "signWrongs = 0\n",
    "wrongValues = []\n",
    "#wrongThings = []\n",
    "for i in testResults:\n",
    "\t# i = (outputTensor, expectedValue)\n",
    "\texpectedMean = i[0][0].item()\n",
    "\tstddev = math.sqrt(i[0][1].item())\n",
    "\texpected = i[1]\n",
    "\n",
    "\tamountOfVariances = math.ceil(\n",
    "\t\tabs(expected - expectedMean) / stddev\n",
    "\t)\n",
    "\tif amountOfVariances not in offsets:\n",
    "\t\toffsets[amountOfVariances] = 1\n",
    "\telse:\n",
    "\t\toffsets[amountOfVariances] += 1\n",
    "\tif math.copysign(1, i[0][0].item()) != math.copysign(1, i[1]):\n",
    "\t\tsignWrongs += 1\n",
    "\t\twrongValues.append(i[0][0].item())\n",
    "\t\t#wrongThings.append((i[0][0].item(), i[0][1].item()))\n",
    "print(signWrongs)\n",
    "print(offsets)\n",
    "#print(wrongValues)\n",
    "print(sum(wrongValues)/len(wrongValues))\n",
    "print(max([abs(x) for x in wrongValues]))\n",
    "\n",
    "#print(wrongThings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRINT PARAMETERS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, estimator.model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "with open('params.txt', 'w') as f:\n",
    "\tf.write(list(filter(lambda p: p.requires_grad, estimator.model.parameters())).__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime Measurement #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData = testData + trainData\n",
    "\n",
    "estimator.model.eval()\n",
    "start = time.time()\n",
    "for s in fullData:\n",
    "\tx = estimator.forward(s[0])\n",
    "end = time.time()\n",
    "print(f\"Estimator took {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime measurement full monitor ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Conversion (requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData = trainData + testData\n",
    "fullSignalData = [stl.signals.SignalList([\n",
    "\tSignal('c', times=[i * 50 / (len(sample[0][:,0].squeeze())-1) for i in range(len(sample[0][:,0].squeeze()))], values=sample[0][:,0].squeeze().tolist()),\n",
    "\tSignal('p', times=[i * 50 / (len(sample[0][:,1].squeeze())-1) for i in range(len(sample[0][:,1].squeeze()))], values=sample[0][:,1].squeeze().tolist())\n",
    "]) for sample in fullData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model.eval()\n",
    "\n",
    "formula = \"(([]{0,50}(0.5-c))^([]{0,50}(0.5+c)))^(([]{0,50}(0.5-p))^([]{0,50}(0.5+p)))\"\n",
    "parser = stl.parsing.stlParser(a4.CommonTokenStream(stl.parsing.stlLexer(a4.InputStream(formula))))\n",
    "tree = parser.content()\n",
    "listener = stl.parsing.CustomStlListener()\n",
    "walker = a4.ParseTreeWalker()\n",
    "walker.walk(listener, tree)\n",
    "parser.addParseListener(listener)\n",
    "stlTree = listener.stlTree\n",
    "\n",
    "start = time.time()\n",
    "count = 0\n",
    "estTime = 0\n",
    "cmpTime = 0\n",
    "badcount = 0\n",
    "for index in range(len(fullData)):\n",
    "\tsample = fullData[index]\n",
    "\tst = time.time()\n",
    "\tprediction = estimator.forward(sample[0])\n",
    "\testTime += time.time() - st\n",
    "\t# mean, variance = prediction[0][0].item(), prediction[0][1].item()\n",
    "\tif torch.abs(prediction[0][0]) < 2 * torch.sqrt(prediction[0][1]):\n",
    "\t\tcount += 1\n",
    "\t\t# If zero reachable within two stddev, compute the traditional computation\n",
    "\t\tst = time.time()\n",
    "\t\trobustness = stlTree.validate(fullSignalData[index])\n",
    "\t\tcmpTime += time.time() - st\n",
    "\telif sample[1] * prediction[0][0] < 0: # indicates opposite sign\n",
    "\t\tbadcount += 1\n",
    "print(count)\n",
    "end = time.time()\n",
    "print(f\"Estimator took {end - start}\")\n",
    "print(f\"\\tOf which {estTime} in estimation\")\n",
    "print(f\"\\tAnd {cmpTime} in computation\")\n",
    "\n",
    "print(badcount)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa8f3a89dcc425de29eb1b7a61e6b6ae1d283c6e1f00cdd1571d1eefbdb7c48e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
